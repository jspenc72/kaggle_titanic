{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import math as m\n",
    "from statsmodels import robust\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import make_scorer, accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import Imputer, LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Currently getting warning : \n",
    "# label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. \n",
    "# Returning False, but in future this will result in an error. Use 'array.size > 0' to check that \n",
    "# an array is not empty.\n",
    "#\n",
    "# ... which was apparently fixed pre sklearn 0.19.1 but didn't make it into the build, suppressing for now...\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv('./data/train.csv', header=0)\n",
    "test_df = pd.read_csv('./data/test.csv', header=0)\n",
    "\n",
    "CV_FOLDS = 10\n",
    "SCORER = make_scorer(accuracy_score)\n",
    "UNKNOWN_VALUE = \"XX\"\n",
    "LABEL_COL = 'Survived'\n",
    "ID_COL = 'PassengerId'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prefix(input_string):\n",
    "    first_period_index = str.index(input_string, \".\")\n",
    "    prev_space_index = input_string.rfind(\" \", 0, first_period_index-1)\n",
    "    return input_string[prev_space_index+1:first_period_index+1]\n",
    "\n",
    "def get_ticket_code(ticket):\n",
    "    if (ticket != \"\" and not pd.isnull(ticket)):        \n",
    "        ticket_split = ticket.split(\" \")\n",
    "        if len(ticket_split) == 1:\n",
    "            return UNKNOWN_VALUE\n",
    "        else:\n",
    "            return ticket_split[0].strip().replace(\".\",\"\").replace(\"/\",\"\").lower()\n",
    "    else:\n",
    "        return UNKNOWN_VALUE\n",
    "\n",
    "# cols which will be used as features (directly (Fare) or indirectly (Name -> prefix))\n",
    "cols_to_use = ['Fare', 'SibSp', 'Parch', 'Pclass', 'Sex', 'Embarked', 'Name', 'Ticket']\n",
    "\n",
    "# use test and train to ensure we see all possible values\n",
    "train_and_test_X = train_df.append(test_df)\n",
    "train_and_test_X = train_and_test_X.reset_index()\n",
    "\n",
    "# couple items are documented as wrong, why not fix it\n",
    "train_and_test_X.SibSp[train_and_test_X.PassengerId==280] = 0\n",
    "train_and_test_X.Parch[train_and_test_X.PassengerId==280] = 2\n",
    "train_and_test_X.SibSp[train_and_test_X.PassengerId==1284] = 1\n",
    "train_and_test_X.Parch[train_and_test_X.PassengerId==1284] = 1\n",
    "\n",
    "train_and_test_X = train_and_test_X[cols_to_use]\n",
    "\n",
    "# new features\n",
    "train_and_test_X['Prefix'] = train_and_test_X['Name'].apply(get_prefix)\n",
    "train_and_test_X['TicketCode'] = train_and_test_X['Ticket'].apply(get_ticket_code)\n",
    "\n",
    "# Overall Family Size\n",
    "train_and_test_X['ParchSibSp'] = train_and_test_X[['Parch', 'SibSp']].apply(lambda r : r[0] + r[1], axis=1)\n",
    "\n",
    "# These two lists control what raw features will be used, and how they will be treated\n",
    "numeric_cols = ['Fare', 'ParchSibSp', 'Pclass']\n",
    "categorical_cols = ['Sex', 'Prefix', 'Embarked', 'TicketCode']\n",
    "\n",
    "#subset to cols we'll use as features\n",
    "train_and_test_X = train_and_test_X[numeric_cols + categorical_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Impute a particular column grouping by another column\n",
    "# Fill in with median if numeric, most common value otherwise\n",
    "#\n",
    "class ContextualImputer(TransformerMixin):\n",
    "    \n",
    "    # constructor params:\n",
    "    #  col : col to impute\n",
    "    #  byCol : column within which to impute 'col'\n",
    "    def __init__(self, col, byCol):\n",
    "        self.col = col\n",
    "        self.byCol = byCol\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.bycolumn_unique_values = np.unique(X[self.byCol].values)\n",
    "        \n",
    "        if X[self.col].dtype != np.dtype('O'):\n",
    "            bycolumn_fill_values = [np.median((X[pd.notnull(X[self.col]) & (X[self.byCol] == bycolumn_unique_value2)][self.col])) \n",
    "                                  for bycolumn_unique_value2 in self.bycolumn_unique_values]\n",
    "        else:\n",
    "            bycolumn_fill_values = [X[pd.notnull(X[self.col]) & (X[self.byCol] == bycolumn_unique_value)][self.col].value_counts().index[0]  \n",
    "                                  for bycolumn_unique_value in self.bycolumn_unique_values]\n",
    "\n",
    "        bycolumn_values_fill_zipped = np.column_stack((self.bycolumn_unique_values, bycolumn_fill_values))\n",
    "        self.bycolumn_values_fill_zipped_dict = dict(bycolumn_values_fill_zipped)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        def fill(row):\n",
    "            if pd.isnull(row[self.col]):\n",
    "                return self.bycolumn_values_fill_zipped_dict[row[self.byCol]]\n",
    "            else:\n",
    "                return row[self.col]\n",
    "\n",
    "        X[self.col] = X[self.col].fillna(X.apply(fill, axis=1))\n",
    "        return X\n",
    "\n",
    "#\n",
    "# Typical imputer found around the web.  Most common value for categoricals,\n",
    "# median for numerics.  \n",
    "#\n",
    "# We'll use it for categoricals, and above customer imputer for numerics\n",
    "#\n",
    "class CategImputer(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Impute missing values.\n",
    "        If the Series is of dtype Object, then impute with the most frequent object.\n",
    "        If the Series is not of dtype Object, then impute with the mean.  \n",
    "        \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "                               if X[c].dtype == np.dtype('O')\n",
    "                               else X[c].median() for c in X], index=X.columns)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)\n",
    "    \n",
    "#\n",
    "# Imputation of missing vals\n",
    "#\n",
    "# custom imputation for Fare by class, was useful for age too (by prefix for example),\n",
    "# but I ended up not using age\n",
    "all_X_imputed = ContextualImputer('Fare', 'Pclass').fit_transform(train_and_test_X)\n",
    "\n",
    "# Only two missing values and other features most resembled the 'C' group\n",
    "train_and_test_X['Embarked'] = np.where(train_and_test_X['Embarked'].isnull(), 'C', train_and_test_X['Embarked'])\n",
    "\n",
    "# most common value for remaining categoricals\n",
    "all_X_imputed = CategImputer().fit_transform(all_X_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_X_encoded = all_X_imputed\n",
    "\n",
    "# Onehot encoding of cateogricals using get_dummies\n",
    "# Although Pclass is a number, it's really a code and we'll treat it as such\n",
    "for categorical_col in ['Pclass', 'Embarked']:\n",
    "    all_X_encoded = pd.concat([pd.get_dummies(all_X_imputed[categorical_col], \n",
    "                                              prefix=categorical_col, drop_first=True), \n",
    "                               all_X_encoded], axis=1)\n",
    "\n",
    "# can't leave categoricals numbers, Sex is binary so just map to 0/1\n",
    "all_X_encoded['Sex'] = all_X_encoded['Sex'].map({'male':0, 'female': 1})\n",
    "\n",
    "#\n",
    "# Bin some features by survival likelihood\n",
    "#\n",
    "all_X_encoded[\"ParchSibSp_0\"] = all_X_encoded[\"ParchSibSp\"].map(lambda s: 1 if s == 0 else 0)\n",
    "all_X_encoded[\"ParchSibSp_12\"] = all_X_encoded[\"ParchSibSp\"].map(lambda s: 1 if (s == 1 or s == 2) else 0)\n",
    "all_X_encoded[\"ParchSibSp_3\"] = all_X_encoded[\"ParchSibSp\"].map(lambda s: 1 if (s == 3) else 0)\n",
    "all_X_encoded[\"ParchSibSp_gt3\"] = all_X_encoded[\"ParchSibSp\"].map(lambda s: 1 if s > 3 else 0)\n",
    "\n",
    "# Prefix.  \n",
    "# Leaving out Master since it actually made a diff for XGB. \n",
    "# Assuming this is due to its redundancy with Male/Single(?)\n",
    "high_prob = ['Mme.', 'Ms.', 'Lady.', 'Sir.', 'Mlle.', 'Countess']\n",
    "medhigh_prob = ['Mrs.', 'Miss.']\n",
    "med_prob = ['Dr.', 'Major.', 'Col.', 'Mrs.']\n",
    "low_prob = ['Mr.']\n",
    "very_low_prob = ['Capt.', 'Don.', 'Rev.', 'Jonkheer.']\n",
    "known_probs = high_prob + med_prob + low_prob + very_low_prob\n",
    "all_X_encoded[\"Prefix_high\"] = all_X_encoded[\"Prefix\"].map(lambda s: 1 if s in high_prob else 0)\n",
    "all_X_encoded[\"Prefix_medhigh_prob\"] = all_X_encoded[\"Prefix\"].map(lambda s: 1 if s in medhigh_prob else 0)\n",
    "all_X_encoded[\"Prefix_med\"] = all_X_encoded[\"Prefix\"].map(lambda s: 1 if s in med_prob else 0)\n",
    "all_X_encoded[\"Prefix_low\"] = all_X_encoded[\"Prefix\"].map(lambda s: 1 if s in low_prob else 0)\n",
    "all_X_encoded[\"Prefix_very_low\"] = all_X_encoded[\"Prefix\"].map(lambda s: 1 if s in very_low_prob else 0)\n",
    "\n",
    "# TicketCode\n",
    "high_prob = ['swpp', 'sc']\n",
    "med_high_prob = ['pc', 'pp', 'fcc', 'scah']\n",
    "med_prob = ['stono2', 'XX', 'ca', 'scparis', 'stono', 'c', 'ppp']\n",
    "low_prob = ['a5', 'soc', 'wc', 'sotonoq', 'wep']\n",
    "very_low_prob = ['sca4', 'a4', 'sp', 'spo', 'fa', 'scow', 'as', 'sopp', 'fc', 'sotono2', 'casoton']\n",
    "known_probs = high_prob + med_high_prob + med_prob + low_prob + very_low_prob \n",
    "all_X_encoded[\"TicketCode_high\"] = all_X_encoded[\"TicketCode\"].map(lambda s: 1 if s in high_prob else 0)\n",
    "all_X_encoded[\"TicketCode_medhigh\"] = all_X_encoded[\"TicketCode\"].map(lambda s: 1 if s in med_high_prob else 0)\n",
    "all_X_encoded[\"TicketCode_med\"] = all_X_encoded[\"TicketCode\"].map(lambda s: 1 if s in med_prob else 0)\n",
    "all_X_encoded[\"TicketCode_low\"] = all_X_encoded[\"TicketCode\"].map(lambda s: 1 if s in low_prob else 0)\n",
    "all_X_encoded[\"TicketCode_very_low\"] = all_X_encoded[\"TicketCode\"].map(lambda s: 1 if s in very_low_prob else 0)\n",
    "\n",
    "all_X_final = all_X_encoded\n",
    "\n",
    "all_X_final.drop(\"Prefix\", inplace=True, axis=1)\n",
    "all_X_final.drop(\"TicketCode\", inplace=True, axis=1)\n",
    "all_X_final.drop(\"Embarked\", inplace=True, axis=1)\n",
    "all_X_final.drop(\"Pclass\", inplace=True, axis=1)\n",
    "\n",
    "test_X = all_X_final[all_X_final.shape[0]-test_df.shape[0]::]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   3 out of  10 | elapsed:    0.1s remaining:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV : best estimator accuracy : 0.8451178451178452\n",
      "CV : best estimator std : 0.02811520868332541\n",
      "CV : best estimator range (.95) : 0.7888874277511944 - 0.901348262484496\n",
      "CV : best estimator range (.99) : 0.760772219067869 - 0.9294634711678214\n",
      "CV : best estimator params : {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'reg_alpha': 0.75, 'reg_lambda': 0.75}\n",
      "CV : xgbc_best : XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.75, reg_lambda=0.75, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "XGBoost : CV elapsed time : 0.5577900409698486\n",
      "Last run time : 2018-04-16 16:17:32.884099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "parameters = {\n",
    "   'learning_rate': [.1],\n",
    "# 'learning_rate': [.01, 0.1, .2, .25, .5, .75, 1], \n",
    "     'max_depth': [3],\n",
    "#'max_depth': [2, 3, 4, 5, 6],\n",
    "#        'min_child_weight': [1],\n",
    "#'min_child_weight': [1, 2, 3, 4, 5],\n",
    "\n",
    "'n_estimators': [100],\n",
    "#'n_estimators': [75, 100, 125, 150, 200, 225],\n",
    "#    'subsample' : [.9],\n",
    "#'subsample' : [.6, .7, .8, .9, 1.0],\n",
    "#       'colsample_bytree' : [.6],\n",
    "#'colsample_bytree' : [.6, .7, .8, .9, 1.0],\n",
    "#      'gamma': [0.1],\n",
    "#'gamma': [0, .01, .1, .2, .3, .4],\n",
    "\n",
    "       'reg_alpha':[.75],\n",
    "#'reg_alpha':[0.0, .1, .25, .5, .75, 1],\n",
    "       'reg_lambda':[.75]\n",
    "#'reg_lambda':[0.0, .1, .25, .5, .75, 1]\n",
    "    }\n",
    "\n",
    "grid_obj = GridSearchCV(xgb.XGBClassifier(), \n",
    "                        parameters, \n",
    "                        scoring=SCORER, \n",
    "                        cv=CV_FOLDS, \n",
    "                        verbose=1, \n",
    "                        n_jobs=4)\n",
    "\n",
    "xgbc_best = grid_obj.fit(all_X_final[0:train_df.shape[0]], train_df[LABEL_COL]).best_estimator_\n",
    "print(\"CV : best estimator accuracy : {0}\".format(grid_obj.best_score_))\n",
    "print(\"CV : best estimator std : {0}\".format(grid_obj.cv_results_['std_test_score'][grid_obj.best_index_]))\n",
    "print(\"CV : best estimator range (.95) : {0} - {1}\".format(grid_obj.best_score_ - 2*grid_obj.cv_results_['std_test_score'][grid_obj.best_index_], grid_obj.best_score_ + 2*grid_obj.cv_results_['std_test_score'][grid_obj.best_index_]))\n",
    "print(\"CV : best estimator range (.99) : {0} - {1}\".format(grid_obj.best_score_ - 3*grid_obj.cv_results_['std_test_score'][grid_obj.best_index_], grid_obj.best_score_ + 3*grid_obj.cv_results_['std_test_score'][grid_obj.best_index_]))\n",
    "print(\"CV : best estimator params : {0}\".format(grid_obj.best_params_))\n",
    "print(\"CV : xgbc_best : {0}\".format(xgbc_best))\n",
    "\n",
    "xgb_final_predictions = xgbc_best.predict(test_X)\n",
    "xgb_final_predictions_df = pd.DataFrame({ 'PassengerId': test_df['PassengerId'], 'Survived': xgb_final_predictions})\n",
    "xgb_final_predictions_df.to_csv(\"submission_xgb.csv\", index=False)\n",
    "print(\"XGBoost : CV elapsed time : {0}\".format((time.time() - start_time)))\n",
    "print(\"Last run time : {0}\".format(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   3 out of  10 | elapsed:    0.2s remaining:    0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator accuracy : 0.8316498316498316\n",
      "CV : best estimator std : 0.025699644490569704\n",
      "CV : best estimator range (.95) : 0.7802505426686922 - 0.8830491206309711\n",
      "CV : best estimator range (.99) : 0.7545508981781225 - 0.9087487651215408\n",
      "best estimator params : {'max_depth': 4, 'max_features': 5, 'n_estimators': 100}\n",
      "etc_best : ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=4, max_features=5, max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
      "elapsed time : 0.815263032913208\n",
      "Last run time : 2018-04-16 16:17:35.312809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "start_time = time.time()\n",
    "\n",
    "parameters = {\n",
    "    \"max_depth\": [4],\n",
    "#    \"max_depth\": [3, 4, 5, 6, 7, 8],\n",
    "    \"max_features\": [5],\n",
    "#    \"max_features\": [3, 4, 5, 6, 7, 8, 9, 10, 12],\n",
    "\n",
    "#      \"min_samples_leaf\": [1],\n",
    "#\"min_samples_leaf\": [1, 2, 3, 4, 5],\n",
    "#      \"min_samples_split\": [2],\n",
    "#\"min_samples_split\": [2, 3, 4, 5],\n",
    "\n",
    "# #   \"min_weight_fraction_leaf\": [.01],\n",
    "#\"min_weight_fraction_leaf\": [0, .01, .1, .2],\n",
    "       \"n_estimators\" :[100],\n",
    "#\"n_estimators\" :[25, 50, 75, 100, 125, 150, 200, 250, 300],\n",
    "    }\n",
    "\n",
    "grid_obj = GridSearchCV(ExtraTreesClassifier(random_state=0), \n",
    "                        parameters, \n",
    "                        scoring=SCORER, \n",
    "                        cv=CV_FOLDS, \n",
    "                        verbose=1,\n",
    "                       n_jobs=4)\n",
    "\n",
    "etc_best = grid_obj.fit(all_X_final[0:train_df.shape[0]], train_df[LABEL_COL]).best_estimator_\n",
    "print(\"best estimator accuracy : {0}\".format(grid_obj.best_score_))\n",
    "print(\"CV : best estimator std : {0}\".format(grid_obj.cv_results_['std_test_score'][grid_obj.best_index_]))\n",
    "print(\"CV : best estimator range (.95) : {0} - {1}\".format(grid_obj.best_score_ - 2*grid_obj.cv_results_['std_test_score'][grid_obj.best_index_], grid_obj.best_score_ + 2*grid_obj.cv_results_['std_test_score'][grid_obj.best_index_]))\n",
    "print(\"CV : best estimator range (.99) : {0} - {1}\".format(grid_obj.best_score_ - 3*grid_obj.cv_results_['std_test_score'][grid_obj.best_index_], grid_obj.best_score_ + 3*grid_obj.cv_results_['std_test_score'][grid_obj.best_index_]))\n",
    "print(\"best estimator params : {0}\".format(grid_obj.best_params_))\n",
    "print(\"etc_best : {0}\".format(etc_best))\n",
    "\n",
    "etc_final_predictions = etc_best.predict(test_X)\n",
    "etc_final_predictions_df = pd.DataFrame({ 'PassengerId': test_df['PassengerId'], 'Survived': etc_final_predictions})\n",
    "etc_final_predictions_df.to_csv(\"submission_etc.csv\", index=False)\n",
    "print(\"elapsed time : {0}\".format((time.time() - start_time)))\n",
    "print(\"Last run time : {0}\".format(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "best estimator accuracy : 0.8327721661054994\n",
      "CV : best estimator std : 0.025488819380169093\n",
      "CV : best estimator range (.95) : 0.7817945273451612 - 0.8837498048658377\n",
      "CV : best estimator range (.99) : 0.7563057079649922 - 0.9092386242460067\n",
      "best estimator params : {'C': 3, 'max_iter': 10, 'penalty': 'l1'}\n",
      "lr_best : LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=10, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "elapsed time : 0.17826414108276367\n",
      "Last run time : 2018-04-16 16:17:36.263247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "start_time = time.time()\n",
    "\n",
    "parameters = {\n",
    "    \"max_iter\" : [10],\n",
    "#    \"max_iter\" : [5, 10, 25, 50, 100, 200],\n",
    "    \"penalty\" : ['l1'],\n",
    "#    \"penalty\" : ['l1', 'l2'],\n",
    "    \"C\" : [3],\n",
    "#    \"C\" : [.01, .1, .5, 1, 2, 3, 4, 5, 10],\n",
    "#    \"class_weight\" : [\"balanced\", None]\n",
    "}\n",
    "\n",
    "# Run the grid search over cv split data\n",
    "grid_obj = GridSearchCV(LogisticRegression(), \n",
    "                        parameters, \n",
    "                        scoring=SCORER, \n",
    "                        cv=CV_FOLDS, \n",
    "                        verbose=1,\n",
    "                        n_jobs=2)\n",
    "\n",
    "lr_best = grid_obj.fit(all_X_final[0:train_df.shape[0]], train_df[LABEL_COL]).best_estimator_\n",
    "print(\"best estimator accuracy : {0}\".format(grid_obj.best_score_))\n",
    "print(\"CV : best estimator std : {0}\".format(grid_obj.cv_results_['std_test_score'][grid_obj.best_index_]))\n",
    "print(\"CV : best estimator range (.95) : {0} - {1}\".format(grid_obj.best_score_ - 2*grid_obj.cv_results_['std_test_score'][grid_obj.best_index_], grid_obj.best_score_ + 2*grid_obj.cv_results_['std_test_score'][grid_obj.best_index_]))\n",
    "print(\"CV : best estimator range (.99) : {0} - {1}\".format(grid_obj.best_score_ - 3*grid_obj.cv_results_['std_test_score'][grid_obj.best_index_], grid_obj.best_score_ + 3*grid_obj.cv_results_['std_test_score'][grid_obj.best_index_]))\n",
    "print(\"best estimator params : {0}\".format(grid_obj.best_params_))\n",
    "print(\"lr_best : {0}\".format(lr_best))\n",
    "\n",
    "\n",
    "lr_final_predictions = lr_best.predict(test_X)\n",
    "lr_final_predictions_df = pd.DataFrame({ 'PassengerId': test_df['PassengerId'], 'Survived': lr_final_predictions})\n",
    "lr_final_predictions_df.to_csv(\"submission_lr.csv\", index=False)\n",
    "print(\"elapsed time : {0}\".format((time.time() - start_time)))\n",
    "print(\"Last run time : {0}\".format(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   3 out of  10 | elapsed:    0.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator accuracy : 0.8002244668911336\n",
      "CV : best estimator std : 0.018644291935906422\n",
      "CV : best estimator range (.95) : 0.7629358830193207 - 0.8375130507629465\n",
      "CV : best estimator range (.99) : 0.7442915910834144 - 0.8561573426988528\n",
      "CV : best estimator params : {'C': 4, 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000}\n",
      "CV : svc_best : SVC(C=4, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "  max_iter=10000, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "elapsed time : 0.9545049667358398\n",
      "Last run time : 2018-04-16 16:17:38.400520\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "start_time = time.time()\n",
    "\n",
    "parameters = {\n",
    "    'kernel': ['rbf'], \n",
    "#    'kernel': ['linear', 'rbf', 'poly'], \n",
    "#    \"degree\" : [2],\n",
    "#    \"degree\" : [2, 3, 4],\n",
    "    # this ran seemingly forever without max_iter\n",
    "    'max_iter' : [10000],\n",
    "   'gamma': [.01],\n",
    "#  'gamma': [ 0, .0001, 0.001, 0.01, 0.1, .2, .3],\n",
    "   'C': [4],\n",
    "#  'C': [.1, .5, 1, 2, 3, 4, 10, 20],\n",
    "}\n",
    "\n",
    "grid_obj = GridSearchCV(SVC(probability=True), \n",
    "                        parameters, \n",
    "                        scoring=SCORER, \n",
    "                        cv=CV_FOLDS, \n",
    "                        verbose=1,\n",
    "                        n_jobs=4)\n",
    "svc_best = grid_obj.fit(all_X_final[0:train_df.shape[0]], train_df[LABEL_COL]).best_estimator_\n",
    "print(\"best estimator accuracy : {0}\".format(grid_obj.best_score_))\n",
    "print(\"CV : best estimator std : {0}\".format(grid_obj.cv_results_['std_test_score'][grid_obj.best_index_]))\n",
    "print(\"CV : best estimator range (.95) : {0} - {1}\".format(grid_obj.best_score_ - 2*grid_obj.cv_results_['std_test_score'][grid_obj.best_index_], grid_obj.best_score_ + 2*grid_obj.cv_results_['std_test_score'][grid_obj.best_index_]))\n",
    "print(\"CV : best estimator range (.99) : {0} - {1}\".format(grid_obj.best_score_ - 3*grid_obj.cv_results_['std_test_score'][grid_obj.best_index_], grid_obj.best_score_ + 3*grid_obj.cv_results_['std_test_score'][grid_obj.best_index_]))\n",
    "print(\"CV : best estimator params : {0}\".format(grid_obj.best_params_))\n",
    "print(\"CV : svc_best : {0}\".format(svc_best))\n",
    "\n",
    "\n",
    "svc_final_predictions = svc_best.predict(test_X)\n",
    "svc_final_predictions_df = pd.DataFrame({ 'PassengerId': test_df['PassengerId'], 'Survived': svc_final_predictions})\n",
    "svc_final_predictions_df.to_csv(\"submission_svc.csv\", index=False)\n",
    "print(\"elapsed time : {0}\".format((time.time() - start_time)))\n",
    "print(\"Last run time : {0}\".format(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "best estimator accuracy : 0.8226711560044894\n",
      "CV : best estimator std : 0.027583909030662858\n",
      "CV : best estimator range (.95) : 0.7675033379431636 - 0.8778389740658151\n",
      "CV : best estimator range (.99) : 0.7399194289125008 - 0.9054228830964779\n",
      "CV : best estimator params : {'algorithm': 'SAMME.R', 'base_estimator__criterion': 'entropy', 'base_estimator__splitter': 'best', 'learning_rate': 0.1, 'n_estimators': 10}\n",
      "CV : ada_best : AdaBoostClassifier(algorithm='SAMME.R',\n",
      "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'),\n",
      "          learning_rate=0.1, n_estimators=10, random_state=None)\n",
      "elapsed time : 0.31580400466918945\n",
      "Last run time : 2018-04-16 16:17:38.849622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   3 out of  10 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "start_time = time.time()\n",
    "\n",
    "parameters = {\n",
    "    \"base_estimator__criterion\" : [\"entropy\"],\n",
    "#    \"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "    \"base_estimator__splitter\" :   [\"best\"],\n",
    "#    \"base_estimator__splitter\" :   [\"best\", \"random\"],\n",
    "    \"n_estimators\": [10],\n",
    "#    \"n_estimators\": [1, 2, 3, 4, 5, 10, 20],\n",
    "    \"learning_rate\":  [.1],\n",
    "#    \"learning_rate\":  [0.0001, 0.001, 0.01, 0.1, .2],\n",
    "    \"algorithm\" : ['SAMME.R']\n",
    "#    \"algorithm\" : ['SAMME', 'SAMME.R']\n",
    "}\n",
    "\n",
    "grid_obj = GridSearchCV(AdaBoostClassifier(DecisionTreeClassifier()), \n",
    "                        parameters, \n",
    "                        scoring=SCORER, \n",
    "                        cv=CV_FOLDS,\n",
    "                        verbose=1,\n",
    "                        n_jobs=4)\n",
    "\n",
    "ada_best = grid_obj.fit(all_X_final[0:train_df.shape[0]], train_df[LABEL_COL]).best_estimator_\n",
    "print(\"best estimator accuracy : {0}\".format(grid_obj.best_score_))\n",
    "print(\"CV : best estimator std : {0}\".format(grid_obj.cv_results_['std_test_score'][grid_obj.best_index_]))\n",
    "print(\"CV : best estimator range (.95) : {0} - {1}\".format(grid_obj.best_score_ - 2*grid_obj.cv_results_['std_test_score'][grid_obj.best_index_], grid_obj.best_score_ + 2*grid_obj.cv_results_['std_test_score'][grid_obj.best_index_]))\n",
    "print(\"CV : best estimator range (.99) : {0} - {1}\".format(grid_obj.best_score_ - 3*grid_obj.cv_results_['std_test_score'][grid_obj.best_index_], grid_obj.best_score_ + 3*grid_obj.cv_results_['std_test_score'][grid_obj.best_index_]))\n",
    "print(\"CV : best estimator params : {0}\".format(grid_obj.best_params_))\n",
    "print(\"CV : ada_best : {0}\".format(ada_best))\n",
    "\n",
    "\n",
    "ada_final_predictions = ada_best.predict(test_X)\n",
    "ada_final_predictions_df = pd.DataFrame({ 'PassengerId': test_df['PassengerId'], 'Survived': ada_final_predictions})\n",
    "ada_final_predictions_df.to_csv(\"submission_ada.csv\", index=False)\n",
    "print(\"elapsed time : {0}\".format((time.time() - start_time)))\n",
    "print(\"Last run time : {0}\".format(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   3 out of  10 | elapsed:    0.1s remaining:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator accuracy : 0.8395061728395061\n",
      "CV : best estimator std : 0.030241409731174177\n",
      "CV : best estimator range (.95) : 0.7790233533771578 - 0.8999889923018545\n",
      "CV : best estimator range (.99) : 0.7487819436459836 - 0.9302304020330286\n",
      "CV : best estimator params : {'max_depth': 5, 'max_features': 15, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "CV : rf_best : RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features=15, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "elapsed time : 0.5822420120239258\n",
      "Last run time : 2018-04-16 16:17:40.122693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "start_time = time.time()\n",
    "\n",
    "parameters = {\n",
    "    \"max_depth\": [5],\n",
    "#    \"max_depth\": [2, 3, 4, 5, 6, 10, 15, 20],\n",
    "    \"max_features\" : [15],\n",
    "#    \"max_features\" : [2, 3, 4, 5, 6, 10, 15],\n",
    "    \"min_samples_split\" : [10],\n",
    "#   \"min_samples_split\" : [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    \"n_estimators\": [50],\n",
    "#   \"n_estimators\": [5, 10, 15, 25, 50, 100],\n",
    "}\n",
    "\n",
    "grid_obj = GridSearchCV(RandomForestClassifier(), \n",
    "                        parameters, \n",
    "                        scoring=SCORER, \n",
    "                        cv=CV_FOLDS,\n",
    "                        verbose=1,\n",
    "                        n_jobs=4)\n",
    "rf_best = grid_obj.fit(all_X_final[0:train_df.shape[0]], train_df[LABEL_COL]).best_estimator_\n",
    "print(\"best estimator accuracy : {0}\".format(grid_obj.best_score_))\n",
    "print(\"CV : best estimator std : {0}\".format(grid_obj.cv_results_['std_test_score'][grid_obj.best_index_]))\n",
    "print(\"CV : best estimator range (.95) : {0} - {1}\".format(grid_obj.best_score_ - 2*grid_obj.cv_results_['std_test_score'][grid_obj.best_index_], grid_obj.best_score_ + 2*grid_obj.cv_results_['std_test_score'][grid_obj.best_index_]))\n",
    "print(\"CV : best estimator range (.99) : {0} - {1}\".format(grid_obj.best_score_ - 3*grid_obj.cv_results_['std_test_score'][grid_obj.best_index_], grid_obj.best_score_ + 3*grid_obj.cv_results_['std_test_score'][grid_obj.best_index_]))\n",
    "print(\"CV : best estimator params : {0}\".format(grid_obj.best_params_))\n",
    "print(\"CV : rf_best : {0}\".format(rf_best))\n",
    "\n",
    "rf_final_predictions = rf_best.predict(test_X)\n",
    "rf_final_predictions_df = pd.DataFrame({ 'PassengerId': test_df['PassengerId'], 'Survived': rf_final_predictions})\n",
    "rf_final_predictions_df.to_csv(\"submission_rf.csv\", index=False)\n",
    "print(\"elapsed time : {0}\".format((time.time() - start_time)))\n",
    "print(\"Last run time : {0}\".format(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier : estimators : ['xgbc_best', 'etc_best', 'ada_best', 'svc_best', 'rf_best']\n",
      "\n",
      "elapsed time : 0.3106560707092285\n",
      "Last run time : 2018-04-16 16:17:40.879782\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('xgbc_best', xgbc_best))\n",
    "estimators.append(('etc_best', etc_best))\n",
    "#estimators.append(('lr_best', lr_best)) # this dropped accuracy\n",
    "estimators.append(('ada_best', ada_best))\n",
    "estimators.append(('svc_best', svc_best))\n",
    "estimators.append(('rf_best', rf_best))\n",
    "\n",
    "vc = VotingClassifier(estimators, voting='soft', n_jobs=4)\n",
    "vc.fit(X=all_X_final[0:train_df.shape[0]], y=train_df[LABEL_COL])\n",
    "final_predictions = vc.predict(test_X)\n",
    "final_predictions_df = pd.DataFrame({'PassengerId': test_df['PassengerId'], LABEL_COL: final_predictions })\n",
    "final_predictions_df.to_csv(\"submission_vc.csv\", index=False)\n",
    "print(\"VotingClassifier : estimators : {0}\".format([estimator[0] for estimator in estimators]))\n",
    "print(\"\\nelapsed time : {0}\".format(time.time() - start_time, [estimator[0] for estimator in estimators]))\n",
    "print(\"Last run time : {0}\".format(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploratory code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train shape : (891, 12)\n",
    "# with at least one missing value : (708, 12)\n",
    "# test shape : (418, 11)\n",
    "# with at least one missing value : (331, 11)\n",
    "# train_df[train_df.isnull().any(axis=1)]\n",
    "\n",
    "#\n",
    "# null/missing/nan values\n",
    "#\n",
    "# null_col_counts = []\n",
    "# all_X = train_df[cols_to_use].append(test_df[cols_to_use])\n",
    "# for col in all_X.columns:\n",
    "#     null_col_counts.append((col,train_and_test_X[pd.isnull(all_X[col])].shape[0]))\n",
    "# null_col_counts\n",
    "# [('Age', 263),\n",
    "#  ('Fare', 1),\n",
    "#  ('SibSp', 0),\n",
    "#  ('Parch', 0),\n",
    "#  ('Pclass', 0),\n",
    "#  ('Sex', 0),\n",
    "#  ('Embarked', 2),\n",
    "#  ('Name', 0),\n",
    "#  ('Cabin', 1014)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#corr = pd.concat([train_and_test_X, train_df[LABEL_COL].T], axis=1).corr()\n",
    "\n",
    "# corr = pd.concat([all_X_final, train_df[LABEL_COL].T], axis=1).corr()\n",
    "\n",
    "# # save to csv\n",
    "# corr.to_csv(\"titanic_corr.csv\")\n",
    "\n",
    "# #\n",
    "# # plot correlations in heatmap\n",
    "# #\n",
    "# # Generate a mask for the upper triangle\n",
    "# mask = np.zeros_like(corr, dtype=np.bool)\n",
    "# mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# # Generate a custom diverging colormap\n",
    "# sns.set(style=\"white\")\n",
    "# cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "# fig, ax = plt.subplots(figsize=(16,16)) \n",
    "# sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0, square=True, linewidths=.5, \n",
    "#             cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary stats of numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_and_test_X[0:train_df.shape[0]][numeric_cols].describe()\n",
    "\n",
    "# all_X_final[0:train_df.shape[0]][['Fare', 'ParchSibSp']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import scipy.stats as stats\n",
    "# import seaborn as sns\n",
    "# import matplotlib.mlab as mlab\n",
    "# import matplotlib as mpl\n",
    "\n",
    "# per_row = 3\n",
    "# fig, axs = plt.subplots(figsize=(20, 5), ncols=per_row) \n",
    "\n",
    "# axs[0].set_title(LABEL_COL)\n",
    "# axs[0].hist(train_df[LABEL_COL])\n",
    "# plot_count = 1\n",
    "\n",
    "# for col in all_X_final.columns:\n",
    "#     row_item_count = plot_count % per_row\n",
    "    \n",
    "#     if (row_item_count == 0):\n",
    "#         fig, axs = plt.subplots(figsize=(20, 5), ncols=per_row) \n",
    "        \n",
    "#     axs[row_item_count].set_title(col)\n",
    "\n",
    "#     if col in numeric_cols:\n",
    "#         sns.distplot(all_X_final[col], ax=axs[row_item_count])\n",
    "#     else:\n",
    "#         sns.distplot(all_X_final[col], ax=axs[row_item_count], kde=False)\n",
    "    \n",
    "#     plot_count = plot_count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot distribs by label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # use imputed since it still has original columns\n",
    "# all_X_final_train = pd.concat([all_X_imputed[0:train_df.shape[0]], train_df[LABEL_COL]], axis=1)\n",
    "\n",
    "# # have to melt the dataset and use the variable name as the 'row' var in the FacetGrid\n",
    "# # there will be a different graph pair per variable and each pair is split on the 'col' var (the label)\n",
    "# all_X_final_train_melted = all_X_final_train.melt(id_vars=[LABEL_COL], value_vars=numeric_cols)\n",
    "\n",
    "# g = sns.FacetGrid(all_X_final_train_melted, \n",
    "#                   col='Survived', \n",
    "#                   hue='Survived', \n",
    "#                   row='variable', \n",
    "#                   sharex=False, \n",
    "#                   sharey=False, \n",
    "#                   margin_titles=True,\n",
    "#                   size = 5)\n",
    "# g = g.map(sns.distplot, 'value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts of categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAFgCAYAAACbqJP/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ede0080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#g = sns.factorplot(x=\"Prefix\", data=all_X_imputed, kind=\"count\", size = 12)\n",
    "#g = sns.factorplot(x=\"ParchSibSp\", data=all_X_imputed, kind=\"count\", size = 5)\n",
    "#g = sns.factorplot(x=\"TicketCode\", data=all_X_imputed, kind=\"count\", size = 15)\n",
    "#g = sns.factorplot(x=\"CabinCount\", data=all_X_imputed, kind=\"count\", size = 6)\n",
    "#g = sns.factorplot(x=\"CabinCode\", data=all_X_imputed, kind=\"count\", size = 6)\n",
    "#g = sns.factorplot(x=\"Embarked\", data=all_X_imputed, kind=\"count\", size = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Categoricals distrib by label, shows percentage with label = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAGoCAYAAAATsnHAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJLVkoCRJLRkoSVJLBkqS1NL/BzT3zrmq4D57AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121716b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_with_label = pd.concat([train_and_test_X[0:train_df.shape[0]], train_df[LABEL_COL]], axis=1)\n",
    "\n",
    "#g = sns.factorplot(x=\"Embarked\", y=\"Survived\", data=train_with_label, kind=\"bar\", size = 6)\n",
    "#g = sns.factorplot(x=\"CabinCode\", y=\"Survived\", data=train_with_label, kind=\"bar\", size = 12)\n",
    "#g = sns.factorplot(x=\"TicketCode\", y=\"Survived\", data=train_with_label, kind=\"bar\", size = 16)\n",
    "#g = sns.factorplot(x=\"Prefix\", y=\"Survived\", data=train_with_label, kind=\"bar\", size = 12)\n",
    "#g = sns.factorplot(x=\"CabinCount\", y=\"Survived\", data=train_with_label, kind=\"bar\", size = 6)\n",
    "g = sns.factorplot(x=\"ParchSibSp\", y=\"Survived\", data=train_with_label, kind=\"bar\", size = 6)\n",
    "#g = sns.factorplot(x=\"SibSp\", y=\"Survived\", data=train_with_label, kind=\"bar\", size = 6)\n",
    "#g = sns.factorplot(x=\"Pclass\", y=\"Survived\", data=train_with_label, kind=\"bar\", size = 6)\n",
    "#g = sns.factorplot(x=\"ParchSibSp\", y=\"Survived\", data=train_with_label, kind=\"bar\", size = 6)\n",
    "\n",
    "# Not categoricals, These are messy and take a minute or so, but worth looking at\n",
    "#g = sns.factorplot(x=\"Age\", y=\"Survived\", data=train_with_label, kind=\"bar\", size = 30)\n",
    "#g = sns.factorplot(x=\"Fare\", y=\"Survived\", data=train_with_label, kind=\"bar\", size = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
